{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMxPFLUqwB2mvmk7EXpQjbD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NandiniLReddy/Teaching_AgenticDesign101/blob/main/PromptChaining.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Prompt Chaining implementation\n",
        "\n",
        "## background info\n",
        "\n",
        "implementing prompt chaining requires direct to seqential function calls within the scripts; so some specialized frameworks like control, flow, state and component integration is requried:\n",
        "\n",
        "so some frameworks like langchain, langgraph, crew ai, and google ADK provides such environment:\n",
        "\n",
        "## langchain\n",
        "so langchain and lang-graph are suitable choices as their core apis are explicitly designed for composing chains and graph operations.\n",
        "## langgraph\n",
        "langchain provides foundational abstractions for linear sequences,\n",
        "while langgraph extends these capabilities to support stateful and cyclical computations which are necessary for implementing more sophisticated agentic behaviours"
      ],
      "metadata": {
        "id": "fAQPEk5Up39x"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### this is the implementation of 2 step prompt chaining that functions as a data processing pipeline\n",
        "\n",
        "## initial stage  --  parse unstrcutured text and extract specific information\n",
        "## subsequent stage - receives this structured output and transforms into a structured data format"
      ],
      "metadata": {
        "id": "bAa1QRAnrEiK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## start"
      ],
      "metadata": {
        "id": "ANPvMQfert97"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install langchain langchain-community langchain-openai langgraph"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NNO7myE2qP06",
        "outputId": "ef3dae04-3900-4dc5-8b36-daf7bae689ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.1.0)\n",
            "Collecting langchain-community\n",
            "  Downloading langchain_community-0.4.1-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-openai\n",
            "  Downloading langchain_openai-1.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.3)\n",
            "Requirement already satisfied: langchain-core<2.0.0,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain) (1.1.0)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Collecting langchain-classic<2.0.0,>=1.0.0 (from langchain-community)\n",
            "  Downloading langchain_classic-1.0.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.44)\n",
            "Collecting requests<3.0.0,>=2.32.5 (from langchain-community)\n",
            "  Downloading requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (3.13.2)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (9.1.2)\n",
            "Collecting dataclasses-json<0.7.0,>=0.6.7 (from langchain-community)\n",
            "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.12.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.47)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain-community) (2.0.2)\n",
            "Requirement already satisfied: openai<3.0.0,>=1.109.1 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (2.8.1)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: langgraph-checkpoint<4.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.0.1)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.5)\n",
            "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.2 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.2.10)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.22.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting langchain-text-splitters<2.0.0,>=1.0.0 (from langchain-classic<2.0.0,>=1.0.0->langchain-community)\n",
            "  Downloading langchain_text_splitters-1.0.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<26.0.0,>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (25.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain-core<2.0.0,>=1.1.0->langchain) (4.15.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<4.0.0,>=2.1.0->langgraph) (1.12.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.3.0,>=0.2.2->langgraph) (3.11.4)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain-community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.11.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (0.12.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=1.109.1->langchain-openai) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain-community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain-community) (2025.11.12)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain-community) (3.2.4)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain-openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.3.0,>=0.2.2->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain-core<2.0.0,>=1.1.0->langchain) (3.0.0)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain-community)\n",
            "  Downloading mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
            "Downloading langchain_community-0.4.1-py3-none-any.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_openai-1.1.0-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.3/84.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
            "Downloading langchain_classic-1.0.0-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.5-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.7/64.7 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langchain_text_splitters-1.0.0-py3-none-any.whl (33 kB)\n",
            "Downloading marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Downloading mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
            "Installing collected packages: requests, mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain-text-splitters, langchain-openai, langchain-classic, langchain-community\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.4\n",
            "    Uninstalling requests-2.32.4:\n",
            "      Successfully uninstalled requests-2.32.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.7 langchain-classic-1.0.0 langchain-community-0.4.1 langchain-openai-1.1.0 langchain-text-splitters-1.0.0 marshmallow-3.26.1 mypy-extensions-1.1.0 requests-2.32.5 typing-inspect-0.9.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "requests"
                ]
              },
              "id": "e3a1be57f29d425a8d92644794050bc6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ],
      "metadata": {
        "id": "dv7y8IHjrm-3"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9k9Nl5qsCB5",
        "outputId": "aba21951-e032-4c9a-d822-137b2eee0075"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#load llm\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "Mml4w9gKtXuf"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt-1: Extract info\n",
        "prompt_extract = ChatPromptTemplate.from_template(\"Trandform the following specifications from the following text: \\n\\n{text_input}\")"
      ],
      "metadata": {
        "id": "vzuxSHf2E6gm"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#prompt-2: Transform to JSON\n",
        "prompt_transform = ChatPromptTemplate.from_template(\"Transform the following text into a JSON object with 'cpu', 'memory', and 'storage' as keys: \\n\\n{specifications}\")"
      ],
      "metadata": {
        "id": "vqAFHiMXFaDw"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#building chain using LCEL(Langchain expression language)\n",
        "extraction_chain = prompt_extract | llm | StrOutputParser()\n",
        "#the StrOutputParser() converts the LLM's message output into a simple string."
      ],
      "metadata": {
        "id": "XJtns82wFxAt"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "full_chain = (\n",
        "    {\"specifications\": extraction_chain}\n",
        "    | prompt_transform\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")\n",
        "#the full chain passes the output of extraction chain into the 'specifications'"
      ],
      "metadata": {
        "id": "ncTSmQo9GPmB"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#let's run\n",
        "input_text = \"The new laptop model features a 3.5 Ghz octa-core processor, 16GB of RAM, and a 1TB NVMe SSD.\""
      ],
      "metadata": {
        "id": "3fXldG1sGq4I"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_result = full_chain.invoke({\"text_input\": input_text})"
      ],
      "metadata": {
        "id": "agspQRBwG_WD"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(final_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWhQDieIHHwc",
        "outputId": "446eea50-2d60-40b0-8082-c9216199bc99"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"cpu\": \"3.5 Ghz octa-core\",\n",
            "    \"memory\": \"16GB\",\n",
            "    \"storage\": \"1TB NVMe SSD\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# lang-graph looping mechanism:"
      ],
      "metadata": {
        "id": "aN0bxz-bb9E-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated, List\n",
        "from langchain_core.messages import BaseMessage\n",
        "from langgraph.graph import StateGraph, START, END\n",
        "from langgraph.graph.message import add_messages\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "# Define the State for graph\n",
        "# This will be passed between nodes and updated.\n",
        "class GraphState(TypedDict):\n",
        "    \"\"\"\n",
        "    Represents the state of our graph, including initial input and processed text.\n",
        "\n",
        "    Attributes:\n",
        "        initial_input (str): The original text input.\n",
        "        current_text (str): The text being processed and refined through iterations.\n",
        "        iteration_count (int): Counter for loop iterations.\n",
        "    \"\"\"\n",
        "    initial_input: str\n",
        "    current_text: str\n",
        "    iteration_count: int\n",
        "\n",
        "# Define a prompt for refinement within the loop using the existing LLM\n",
        "refinement_prompt = ChatPromptTemplate.from_template(\n",
        "    \"Given the following text, please summarize it more concisely or refine its key points. This is refinement iteration {iteration_count}.\\n\\nText: {input_text}\"\n",
        ")\n",
        "refinement_chain = refinement_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Define the nodes (functions) for our graph\n",
        "def start_node(state: GraphState) -> GraphState:\n",
        "    #Initializes the state with the initial_input and sets iteration_count to 0.\n",
        "    print(\"---> STARTING WORKFLOW <---\")\n",
        "    return {\"current_text\": state['initial_input'], \"iteration_count\": 0}\n",
        "\n",
        "def loop_processing_node(state: GraphState) -> GraphState:\n",
        "    # A node that processes the current_text using the LLM, increments a counter.\n",
        "    print(f\"---> LOOPING/PROCESSING (Iteration: {state['iteration_count'] + 1}) <---\")\n",
        "    current_count = state['iteration_count']\n",
        "    new_count = current_count + 1\n",
        "\n",
        "    text_to_refine = state['current_text']\n",
        "    refined_text = refinement_chain.invoke({\n",
        "        \"input_text\": text_to_refine,\n",
        "        \"iteration_count\": new_count\n",
        "    })\n",
        "    print(f\"   [Iteration {new_count}] Refined text snippet: {refined_text[:70]}...\") # Print a snippet for progress\n",
        "    return {\"current_text\": refined_text, \"iteration_count\": new_count}\n",
        "\n",
        "def final_node(state: GraphState) -> GraphState:\n",
        "    # The end process state\n",
        "    print(\"---> FINALIZING WORKFLOW <---\")\n",
        "    # The final_node simply passes the last refined text along.\n",
        "    return {\"current_text\": state['current_text']}\n",
        "\n",
        "# function to decide the next step after the loop_processing_node\n",
        "def decide_next_step(state: GraphState) -> str:\n",
        "    max_iterations = 3 # Define how many times to loop for this example\n",
        "    if state['iteration_count'] < max_iterations:\n",
        "        print(f\"---DECISION: LOOPING BACK (Current iteration: {state['iteration_count']} / {max_iterations})---\")\n",
        "        return \"loop_processing\"\n",
        "    else:\n",
        "        print(f\"---DECISION: PROCEEDING TO FINAL NODE (Iterations complete: {state['iteration_count']} / {max_iterations})---\")\n",
        "        return \"final_step\"\n",
        "\n",
        "\n",
        "# Build the Langgraph graph\n",
        "workflow = StateGraph(GraphState)\n",
        "\n",
        "# Add the nodes\n",
        "workflow.add_node(\"start_step\", start_node)\n",
        "workflow.add_node(\"loop_processing\", loop_processing_node)\n",
        "workflow.add_node(\"final_step\", final_node)\n",
        "\n",
        "# Set the entry point and edges\n",
        "workflow.add_edge(START, \"start_step\")\n",
        "workflow.add_edge(\"start_step\", \"loop_processing\")\n",
        "\n",
        "# Add conditional edge for the loop\n",
        "workflow.add_conditional_edges(\n",
        "    \"loop_processing\", # From the 'loop_processing' node\n",
        "    decide_next_step, # Use the decision function\n",
        "    {\n",
        "        \"loop_processing\": \"loop_processing\", # If 'loop_processing', loop back to itself\n",
        "        \"final_step\": \"final_step\" # If 'final_step', go to the final node\n",
        "    }\n",
        ")\n",
        "\n",
        "workflow.add_edge(\"final_step\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"Langgraph workflow compiled successfully with an LLM-powered loop example.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDCUHyMQHKDW",
        "outputId": "981de639-a4d5-473c-a192-e503fe00a756"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Langgraph workflow compiled successfully with an LLM-powered loop example.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the Langgraph app with a concrete input text\n",
        "initial_text_for_langgraph = (\n",
        "    \"The quick brown fox jumps over the lazy dog. This sentence is a classic example \"\n",
        "    \"used for testing typewriters and computer keyboards. It contains all the letters \"\n",
        "    \"of the English alphabet. We want to refine and summarize this text multiple times \"\n",
        "    \"to demonstrate a Langgraph loop with an LLM, making it progressively more concise.\"\n",
        ")\n",
        "\n",
        "print(f\"\\nInitial input for Langgraph: {initial_text_for_langgraph[:100]}...\")\n",
        "\n",
        "final_langgraph_state = app.invoke({\n",
        "    \"initial_input\": initial_text_for_langgraph,\n",
        "    \"current_text\": \"\", # 'current_text' will be initialized by start_node with 'initial_input'\n",
        "    \"iteration_count\": 0 # 'iteration_count' will be initialized by start_node\n",
        "})\n",
        "\n",
        "# Print the final processed text from the state\n",
        "print(\"\\nLanggraph Output (Final Processed Text after iterations):\")\n",
        "print(final_langgraph_state['current_text'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbRLsaQ1cgdK",
        "outputId": "809b2da4-0109-4443-ce12-78d42b3c378c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Initial input for Langgraph: The quick brown fox jumps over the lazy dog. This sentence is a classic example used for testing typ...\n",
            "---> STARTING WORKFLOW <---\n",
            "---> LOOPING/PROCESSING (Iteration: 1) <---\n",
            "   [Iteration 1] Refined text snippet: The sentence \"The quick brown fox jumps over the lazy dog\" is commonly...\n",
            "---DECISION: LOOPING BACK (Current iteration: 1 / 3)---\n",
            "---> LOOPING/PROCESSING (Iteration: 2) <---\n",
            "   [Iteration 2] Refined text snippet: \"The quick brown fox jumps over the lazy dog\" is a sentence used to te...\n",
            "---DECISION: LOOPING BACK (Current iteration: 2 / 3)---\n",
            "---> LOOPING/PROCESSING (Iteration: 3) <---\n",
            "   [Iteration 3] Refined text snippet: \"The quick brown fox jumps over the lazy dog\" is a sentence used to te...\n",
            "---DECISION: PROCEEDING TO FINAL NODE (Iterations complete: 3 / 3)---\n",
            "---> FINALIZING WORKFLOW <---\n",
            "\n",
            "Langgraph Output (Final Processed Text after iterations):\n",
            "\"The quick brown fox jumps over the lazy dog\" is a sentence used to test typewriters and keyboards due to its inclusion of all English alphabet letters.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gkd1rRR-cjdD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}